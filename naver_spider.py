import scrapy
from scrapy.crawler import CrawlerProcess
import time


class NaverNewsSpider(scrapy.Spider):
    name = "naver_news"
    start_urls = ['https://news.naver.com/breakingnews/section/101/259']

    custom_settings = {
        "LOG_LEVEL": "ERROR"
    }

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.start_time = time.time()
        self.count = 0

    def parse(self, response):
        links = response.css("ul.sa_list li.sa_item a.sa_text_title::attr(href)").getall()
        for link in links[:60]:  # ìƒìœ„ 30ê°œ ê¸°ì‚¬
            if not link.startswith("http"):
                link = "https://n.news.naver.com" + link
            yield scrapy.Request(link, callback=self.parse_article)

    def parse_article(self, response):
        if self.count == 0:
            print(f"\nğŸ•’ Start: {time.strftime('%X')}")

        title = response.css(".media_end_head_headline").xpath("string()").get()
        content = response.css(".go_trans._article_content").xpath("string()").get()
        date = response.css(".media_end_head_info_datestamp_time._ARTICLE_DATE_TIME::attr(data-date-time)").get()

        print(f"\nğŸ“„ {response.url}")
        print(f"ì œëª©: {title.strip() if title else 'ì—†ìŒ'}")
        print(f"ë³¸ë¬¸ ê¸¸ì´: {len(content.strip()) if content else 0}ì")

        self.count += 1
        if self.count == 5:
            print(f"\nâœ… ì™„ë£Œ. ì´ ì†Œìš” ì‹œê°„: {round(time.time() - self.start_time, 3)}ì´ˆ")

        # âœ… ì—¬ê¸°ì„œ ê²°ê³¼ë¥¼ ë°˜í™˜í•´ì•¼ Scrapyê°€ ì €ì¥í•¨!
        yield {
            "title": title.strip() if title else "ì œëª© ì—†ìŒ",
            "content": content.strip() if content else "",
            "date": date if date else "ë‚ ì§œ ì—†ìŒ",
            "url": response.url,
            "summary_status": "pending"
        }


if __name__ == "__main__":
    process = CrawlerProcess(settings={
        "USER_AGENT": "Mozilla/5.0",
        "LOG_LEVEL": "INFO",
        "FEED_FORMAT": "jsonlines",
        "FEED_URI": "output.json"
    })
    process.crawl(NaverNewsSpider)
    process.start()

